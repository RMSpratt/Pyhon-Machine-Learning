# Kaggle Competition "Machine Learning from Disaster" Submission

## Overview

This notebook was created to test the performance of various machine learning algorithms for classification for the on-going "Machine Learning from Distaster" competition found on Kaggle.

The competition can be found here: https://www.kaggle.com/c/titanic

All of the code in this notebook was written by me, with help from my own research and the O'Reilly textbook found here: https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/

## Libraries Used

All of the following libraries were used for this project and would be required to run through the notebook:

- matplotlib pyplot
- numpy
- pandas
- sklearn
- tensorflow and keras

## Features

After some basic data cleanup and pre-processing, predictions are made on the dataset using a series of classification models including:

- Decision Trees and Random Forests
- Gradient Boosted Classification Tree
- Gaussian Naive-Bayes
- Deep Neural Networks
- KMeans (Clustering for pre-processing)

Some hyperparameter tuning and experiments are made to improve the models used.

My results on predicting the test dataset are included at the end of the notebook.